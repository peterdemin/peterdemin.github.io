<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Precision-Recall - Peter Demin</title><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Solarized Dark Theme for Firefox Reader View" href="65-firefox-reader-solarized-dark.html" /><link rel="prev" title="100 questions for Washington state in Aug 2024" href="63-100q-open.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../_static/shibuya.css?v=44020203" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link media="print" rel="stylesheet" type="text/css" href="../_static/print.css?v=20ff2c19" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=51f15f49" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="Precision-Recall"/>
    <meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../index.html">
      
      
      <strong>Peter Demin</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div class="localtoc"><h3>On this page</h3><ul>
<li><a class="reference internal" href="#background">Background</a></li>
<li><a class="reference internal" href="#first-well-load-a-small-toy-dataset">First, we&#8217;ll load a small toy dataset</a></li>
<li><a class="reference internal" href="#mess-it-up">Mess it up</a></li>
<li><a class="reference internal" href="#split-to-train-and-test-data">Split to train and test data</a></li>
<li><a class="reference internal" href="#boom-weve-got-a-binary-classifier-model">Boom, we&#8217;ve got a binary classifier model</a></li>
<li><a class="reference internal" href="#lets-build-some-curves">Let&#8217;s build some curves</a></li>
<li><a class="reference internal" href="#lets-get-under-the-hood">Let&#8217;s get under the hood</a></li>
<li><a class="reference internal" href="#precision-recall-and-threshold">Precision, recall, and threshold</a></li>
<li><a class="reference internal" href="#english-please">English, please</a></li>
<li><a class="reference internal" href="#computation-details">Computation details</a></li>
<li><a class="reference internal" href="#lets-take-a-look">Let&#8217;s take a look</a></li>
</ul>
</div><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div>
    </div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="w-full max-sm:max-w-full print:pt-6">
    
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../index.html"><span itemprop="name">Peter Demin</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">Precision-Recall</strong>
        <meta itemprop="position" content="2" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div>
    <div class="flex flex-col break-words justify-between">
      <div class="relative min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
  <article class="yue" role="main">
          <section id="precision-recall">
<h1>Precision-Recall<a class="headerlink" href="#precision-recall" title="Link to this heading">¶</a></h1>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Link to this heading">¶</a></h2>
<p>I’m familiarizing myself with basic ML concept of Precision-Recall curve
to build intuition around it.</p>
<p>My source:
<a class="reference external" href="https://scikit-learn.org/dev/auto_examples/model_selection/plot_precision_recall.html">https://scikit-learn.org/dev/auto_examples/model_selection/plot_precision_recall.html</a></p>
</section>
<section id="first-well-load-a-small-toy-dataset">
<h2>First, we’ll load a small toy dataset<a class="headerlink" href="#first-well-load-a-small-toy-dataset" title="Link to this heading">¶</a></h2>
<p>Following the SciKit doc, we’ll use Iris (flower, not part of an eye, or
godess).</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span data-line="2"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
</span><span data-line="3"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
</span><span data-line="4"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics._ranking</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_recall_curve</span>
</span><span data-line="5"><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span>
</span><span data-line="6"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_pipeline</span>
</span><span data-line="7"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
</span><span data-line="8"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LinearSVC</span>
</span><span data-line="9"><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">PrecisionRecallDisplay</span>
</span><span data-line="10">
</span><span data-line="11"><span class="n">random_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</span><span data-line="12">
</span><span data-line="13"><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>
</div>
</section>
<section id="mess-it-up">
<h2>Mess it up<a class="headerlink" href="#mess-it-up" title="Link to this heading">¶</a></h2>
<p>The dataset has 150 records, 4 floating-point flower properties (like
length) for X, and specific flower species label for Y (0, 1, 2). There
are 310 Iris species, but this small dataset has only 3. So, it’s kinda
multilabel. We don’t need that, for precision-recall we need something
binary. So we trim both X and Y to only keep records for <code class="docutils literal notranslate"><span class="pre">Y=0</span></code> aka
False and <code class="docutils literal notranslate"><span class="pre">1</span></code> aka True.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">y</span><span class="o">&lt;</span><span class="mi">2</span><span class="p">]</span>
</span><span data-line="2"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>5.7</td>
      <td>3.0</td>
      <td>4.2</td>
      <td>1.2</td>
    </tr>
    <tr>
      <th>96</th>
      <td>5.7</td>
      <td>2.9</td>
      <td>4.2</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>97</th>
      <td>6.2</td>
      <td>2.9</td>
      <td>4.3</td>
      <td>1.3</td>
    </tr>
    <tr>
      <th>98</th>
      <td>5.1</td>
      <td>2.5</td>
      <td>3.0</td>
      <td>1.1</td>
    </tr>
    <tr>
      <th>99</th>
      <td>5.7</td>
      <td>2.8</td>
      <td>4.1</td>
      <td>1.3</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 4 columns</p>
</div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">y</span>
</span></pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
</span><span data-line="2">       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
</span><span data-line="3">       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
</span><span data-line="4">       <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
</span><span data-line="5">       <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span></pre></div>
</div>
<p>It’s good that it’s binary now, but it’s too easy. If we train a model
on this data now, it will have 100% accuracy, so precision and recall
will look stupied. So, we add noisy features, a whole lot, 100 times
more noise than signal. That will make model to sweat.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2">
</span><span data-line="3"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>394</th>
      <th>395</th>
      <th>396</th>
      <th>397</th>
      <th>398</th>
      <th>399</th>
      <th>400</th>
      <th>401</th>
      <th>402</th>
      <th>403</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>1.788628</td>
      <td>0.436510</td>
      <td>0.096497</td>
      <td>-1.863493</td>
      <td>-0.277388</td>
      <td>-0.354759</td>
      <td>...</td>
      <td>-0.041844</td>
      <td>-0.272736</td>
      <td>-2.676521</td>
      <td>-0.430101</td>
      <td>0.084964</td>
      <td>1.097779</td>
      <td>2.046333</td>
      <td>0.666988</td>
      <td>0.079092</td>
      <td>-0.964763</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>0.089053</td>
      <td>0.778897</td>
      <td>1.264645</td>
      <td>-0.880511</td>
      <td>0.236406</td>
      <td>0.815604</td>
      <td>...</td>
      <td>-0.695176</td>
      <td>0.350235</td>
      <td>0.877156</td>
      <td>-1.154259</td>
      <td>0.167770</td>
      <td>0.247067</td>
      <td>-0.334747</td>
      <td>-0.487161</td>
      <td>-1.854910</td>
      <td>1.148821</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>-0.932924</td>
      <td>-1.240371</td>
      <td>0.657913</td>
      <td>-1.832275</td>
      <td>0.963271</td>
      <td>0.434219</td>
      <td>...</td>
      <td>1.220892</td>
      <td>-2.011595</td>
      <td>-1.504712</td>
      <td>-0.149936</td>
      <td>0.027270</td>
      <td>-1.604372</td>
      <td>-0.674309</td>
      <td>-0.455614</td>
      <td>-0.497364</td>
      <td>-0.518032</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>-0.140283</td>
      <td>0.830035</td>
      <td>0.686235</td>
      <td>0.538731</td>
      <td>0.221271</td>
      <td>-0.770385</td>
      <td>...</td>
      <td>-0.290146</td>
      <td>1.390606</td>
      <td>-1.455962</td>
      <td>0.569578</td>
      <td>0.006109</td>
      <td>0.859871</td>
      <td>-0.444911</td>
      <td>0.753343</td>
      <td>-0.467831</td>
      <td>0.663535</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>-1.922484</td>
      <td>0.528894</td>
      <td>0.782406</td>
      <td>-1.553416</td>
      <td>0.890992</td>
      <td>-1.091646</td>
      <td>...</td>
      <td>1.027371</td>
      <td>-1.060412</td>
      <td>0.745221</td>
      <td>-1.398008</td>
      <td>0.078579</td>
      <td>-1.648937</td>
      <td>-0.172256</td>
      <td>-0.816176</td>
      <td>-1.003245</td>
      <td>0.214830</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>95</th>
      <td>5.7</td>
      <td>3.0</td>
      <td>4.2</td>
      <td>1.2</td>
      <td>-1.048244</td>
      <td>0.062068</td>
      <td>-0.304341</td>
      <td>-0.516236</td>
      <td>0.432118</td>
      <td>0.675260</td>
      <td>...</td>
      <td>1.365158</td>
      <td>0.914614</td>
      <td>0.020456</td>
      <td>-0.314531</td>
      <td>1.468110</td>
      <td>1.703369</td>
      <td>0.409053</td>
      <td>-0.293020</td>
      <td>-0.038827</td>
      <td>-0.759583</td>
    </tr>
    <tr>
      <th>96</th>
      <td>5.7</td>
      <td>2.9</td>
      <td>4.2</td>
      <td>1.3</td>
      <td>1.586293</td>
      <td>-0.490875</td>
      <td>-1.612975</td>
      <td>0.097659</td>
      <td>-0.170520</td>
      <td>1.269662</td>
      <td>...</td>
      <td>-1.006722</td>
      <td>1.040696</td>
      <td>-1.780113</td>
      <td>0.576967</td>
      <td>0.222845</td>
      <td>-0.030648</td>
      <td>1.560297</td>
      <td>1.289232</td>
      <td>0.005855</td>
      <td>-1.530362</td>
    </tr>
    <tr>
      <th>97</th>
      <td>6.2</td>
      <td>2.9</td>
      <td>4.3</td>
      <td>1.3</td>
      <td>0.845536</td>
      <td>-1.045338</td>
      <td>-1.111983</td>
      <td>-0.156758</td>
      <td>0.316664</td>
      <td>0.104065</td>
      <td>...</td>
      <td>0.167184</td>
      <td>0.398998</td>
      <td>0.104368</td>
      <td>1.282921</td>
      <td>-1.973232</td>
      <td>1.331549</td>
      <td>1.144706</td>
      <td>0.378739</td>
      <td>0.497428</td>
      <td>0.880610</td>
    </tr>
    <tr>
      <th>98</th>
      <td>5.1</td>
      <td>2.5</td>
      <td>3.0</td>
      <td>1.1</td>
      <td>0.252259</td>
      <td>1.805827</td>
      <td>-0.505050</td>
      <td>0.088796</td>
      <td>-0.059348</td>
      <td>-1.280433</td>
      <td>...</td>
      <td>-1.077416</td>
      <td>0.696924</td>
      <td>-0.582393</td>
      <td>-1.444338</td>
      <td>-1.175554</td>
      <td>0.287162</td>
      <td>-1.674579</td>
      <td>1.712218</td>
      <td>-0.191547</td>
      <td>-0.217705</td>
    </tr>
    <tr>
      <th>99</th>
      <td>5.7</td>
      <td>2.8</td>
      <td>4.1</td>
      <td>1.3</td>
      <td>-0.843062</td>
      <td>-1.487719</td>
      <td>-0.123779</td>
      <td>0.488852</td>
      <td>-2.191656</td>
      <td>-2.167447</td>
      <td>...</td>
      <td>0.842751</td>
      <td>-1.043519</td>
      <td>1.658296</td>
      <td>-0.766213</td>
      <td>-0.651521</td>
      <td>-3.106978</td>
      <td>-2.366992</td>
      <td>-0.659680</td>
      <td>-1.394787</td>
      <td>1.489548</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 404 columns</p>
</div></section>
<section id="split-to-train-and-test-data">
<h2>Split to train and test data<a class="headerlink" href="#split-to-train-and-test-data" title="Link to this heading">¶</a></h2>
<p>Because we’re such great data scientists, we can’t even think about
testing the model on training data even for educational purposes.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
</span></pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">classifier</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">))</span>
</span><span data-line="2"><span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</span></pre></div>
</div>
</section>
<section id="boom-weve-got-a-binary-classifier-model">
<h2>Boom, we’ve got a binary classifier model<a class="headerlink" href="#boom-weve-got-a-binary-classifier-model" title="Link to this heading">¶</a></h2>
<p>We trained it to predict the likelyhood of smoking pile of garbage being
Iris flower of species number 1. For whatever <code class="docutils literal notranslate"><span class="pre">4</span> <span class="pre">+</span> <span class="pre">40800</span></code> floats we
throw in, the model returns a <em>score</em> of how likely the label is 1.
Let’s take a look at the test output.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">y_score</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span data-line="2"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
</span><span data-line="3">    <span class="s1">&#39;$Y_</span><span class="si">{score}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">y_score</span><span class="p">,</span>
</span><span data-line="4">    <span class="s1">&#39;$Y_</span><span class="si">{true}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>
</span><span data-line="5"><span class="p">})</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_11_0.png" src="../_images/12.64_11_0.png" />
<p>Note how <span class="math notranslate nohighlight">\(Y_{score}\)</span> values are small signed floating point
numbers unlike label, which are either 0 or 1. That’s because the score
doesn’t directly map to the label. Very loosely, it’s a likelyhood of
input having labeled as 1, but not in statistical terms. Let’s say,
there is a correlation. Ok, that might be not the best way to present
this data. How about we plot only scores, and paint it red for label 1
and blue for label 0.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
</span><span data-line="2">    <span class="s1">&#39;$Y_</span><span class="si">{score}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">y_score</span><span class="p">,</span>
</span><span data-line="3">    <span class="s1">&#39;$Y_</span><span class="si">{true}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>
</span><span data-line="4"><span class="p">})</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
</span><span data-line="5">    <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">,</span>
</span><span data-line="6">    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span>
</span><span data-line="7">    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;$Y_</span><span class="si">{score}</span><span class="s1">$&#39;</span><span class="p">,</span>
</span><span data-line="8">    <span class="n">c</span><span class="o">=</span><span class="s1">&#39;$Y_</span><span class="si">{true}</span><span class="s1">$&#39;</span><span class="p">,</span>
</span><span data-line="9">    <span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;bwr&#39;</span><span class="p">,</span>
</span><span data-line="10"><span class="p">);</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_13_0.png" src="../_images/12.64_13_0.png" />
<p>That easier on the eye. We can see that dots at the top are red, dots at
the bottom are blue, and in the middle there’s a mix. To actually tell,
if the score predicts the label to be 1, we need to have a threshold.
With the threshold, we’ll be able to say, okay, everything above this
magical number has label 1.</p>
</section>
<section id="lets-build-some-curves">
<h2>Let’s build some curves<a class="headerlink" href="#lets-build-some-curves" title="Link to this heading">¶</a></h2>
<p>Scikit learn provides handy implementation for drawing the P/R curve,
let’s take a look, so we know what good looks like.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">display</span> <span class="o">=</span> <span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span>
</span><span data-line="2">    <span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;LinearSVC&quot;</span><span class="p">,</span> <span class="n">plot_chance_level</span><span class="o">=</span><span class="kc">True</span>
</span><span data-line="3"><span class="p">)</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;2-class Precision-Recall curve&quot;</span><span class="p">)</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_15_0.png" src="../_images/12.64_15_0.png" />
<p>Beautiful, it’s like a staircase that mostly goes down, except half of
the time it goes up. Definitely tells me a lot about the quality of this
model (it doesn’t).</p>
</section>
<section id="lets-get-under-the-hood">
<h2>Let’s get under the hood<a class="headerlink" href="#lets-get-under-the-hood" title="Link to this heading">¶</a></h2>
<p>First, we’ll sort the “true” labels (y_test) and the predicted scores
(y_score) together by score.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">score_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_score</span><span class="p">)</span>
</span><span data-line="2"><span class="n">sy_score</span> <span class="o">=</span> <span class="n">y_score</span><span class="p">[</span><span class="n">score_indices</span><span class="p">]</span>
</span><span data-line="3"><span class="n">sy_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">score_indices</span><span class="p">]</span>
</span><span data-line="4"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;$Y_</span><span class="si">{true}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">sy_test</span><span class="p">,</span> <span class="s1">&#39;$Y_</span><span class="si">{score}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">sy_score</span><span class="p">})</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_17_0.png" src="../_images/12.64_17_0.png" />
<p>Looks good, very organized. Y_score grows monotonically through its
range, while y_true jumps up and down like crazy. But if we squeeze hard
enough, we’ll see that we have more 1’s on the right side. Actually,
let’s do that color trick again.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="p">(</span><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;$Y_</span><span class="si">{score}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">sy_score</span><span class="p">,</span> <span class="s1">&#39;$Y_</span><span class="si">{true}</span><span class="s1">$&#39;</span><span class="p">:</span> <span class="n">sy_test</span><span class="p">})</span>
</span><span data-line="2">       <span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</span><span data-line="3">       <span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;$Y_</span><span class="si">{score}</span><span class="s1">$&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;$Y_</span><span class="si">{true}</span><span class="s1">$&#39;</span><span class="p">,</span> <span class="n">colormap</span><span class="o">=</span><span class="s1">&#39;bwr&#39;</span><span class="p">));</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_19_0.png" src="../_images/12.64_19_0.png" />
<p>Nice, good job. We can eye-ball that the right threshold for y_score is
around 0, maybe 0.1. The P/R curve will help us pick the right number
for we are the professionals and never eye-ball shit.</p>
</section>
<section id="precision-recall-and-threshold">
<h2>Precision, recall, and threshold<a class="headerlink" href="#precision-recall-and-threshold" title="Link to this heading">¶</a></h2>
<p>Let’s use this handy function from scikit to compute precision, recall,
and threshold. It takes <code class="docutils literal notranslate"><span class="pre">y_test</span></code> as <code class="docutils literal notranslate"><span class="pre">y_true</span></code> - the true test labels
from the dataset, and <code class="docutils literal notranslate"><span class="pre">y_score</span></code> - the predicted score. It returns
three lists of floats of the same length as the score and true labels.</p>
<p>In mathematical notation:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N\)</span> - number of labels, same as number of scores.</p></li>
<li><p><span class="math notranslate nohighlight">\(Y\)</span> - <code class="docutils literal notranslate"><span class="pre">y_true</span></code> - the true (test) label for the record.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{Y}\)</span> - <code class="docutils literal notranslate"><span class="pre">y_score</span></code> - the predicted score.</p></li>
<li><p><span class="math notranslate nohighlight">\(P=\sum_{i=0}^{N}{Y_i}\)</span> - total number of positive test labels.</p></li>
</ul>
<p>It sorts <span class="math notranslate nohighlight">\((Y, \hat{Y})\)</span> pairs by <span class="math notranslate nohighlight">\(\hat{Y}\)</span>. And then
iterates over them while running cumulative sums and doing simple math.
At each iteration of the loop it calculates precision and recall at this
score threshold:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S_i=\hat{Y_{i}}\)</span> - append the current score to the list of
<em>thresholds</em>.</p></li>
<li><p><span class="math notranslate nohighlight">\(T_i=\sum_{k=0}^{i}{(Y_k=1)}\)</span> - cumulative count of <em>true
positives</em> so far.</p></li>
<li><p><span class="math notranslate nohighlight">\(P_i = \frac{T_i}{i}\)</span> - calculate precision at <code class="docutils literal notranslate"><span class="pre">i</span></code> as the
number of true positives divided by the number of records already
seen.</p></li>
<li><p><span class="math notranslate nohighlight">\(R_i = \frac{T_i}{P}\)</span> - calculate recall at <code class="docutils literal notranslate"><span class="pre">i</span></code> as the number
of true positives divided by total number of true labels.</p></li>
</ul>
</section>
<section id="english-please">
<h2>English, please<a class="headerlink" href="#english-please" title="Link to this heading">¶</a></h2>
<p>We want to find a <em>threshold</em> such that any <code class="docutils literal notranslate"><span class="pre">y_score</span></code> above it means
the label is 1. We saw that the prediction is not always accurate and
the data is noisy, so we need to have a number. The number will tell us
how confident we are in the label prediction. The name for it is
precision. When the precision is 1 it means that we never make mistake
by predicting label 1 to something that is label 0. It says nothing
about the other kind of mistake, though. Predicting label 0 to what is
actually label 1 is okay, and doesn’t hurt the precision. Maybe
<em>conservative</em> is a good word, at least <em>asymmetrical</em>. Of course,
everybody in this data science field undestands it, and never bothers to
clarify this detail, just calling it a precision.</p>
<p>Great, back to the threshold. If the treshold is set below the minimum
observed score, it means that everything is label 1, and nothing is
label 0. The recall for such threshold would be 100%, it finds all true
positives. The precision would point to whatever the proportion of
labels is in the dataset. It’s not zero, because it’s sometimes right,
it’s not 100% because it sometimes wrong.</p>
<p>On the other hand, if the score threshold is set above the maximum
observed value, everything gets label 0. Super conservative. The
precision of such system is 100%, because it never make a mistake of
saying that the label is 1 for something that is 0. Those who do
nothing, never make mistakes. The recall is zero, though, as nothing is
ever found.</p>
</section>
<section id="computation-details">
<h2>Computation details<a class="headerlink" href="#computation-details" title="Link to this heading">¶</a></h2>
<p>We want is to calculate precision and recall for every possible score.
But we can’t cover all possible numbers. Luckily, we don’t need to.
Because our evaluation dataset is finite, and between the adjacent
points, the precision and recall is the same. So instead of going over
all possible numbers, we just need to iterate over all observed scores.</p>
<p>For each score we want to know how many points were below it, and how
many of those had the true label of 1. This asks for some sorting. The
trick is to sort all pairs (of score and true label) by score in a
<em>descending order</em>. Then, computing the threshold becomes very easy,
it’s just the score at every point.</p>
<p>For every threshold (assuming unique score thresholds) we want to find
precision and recall. Being at this threshold means that all the points
below are predicted to be labeled 0, and all the points above are
predicted as 1. The precision of such prediction is the number of points
above that are actually labeled 1, divided by the total number of points
above. We, professionals, say: number of <em>true positives</em> divided by sum
of <em>true positives</em> an <em>false positives</em>. In other words, we divide the
real number of positive values by the number of positive predictions,
and that’s the precision at this threshold.</p>
<p>We could have stopped here, you know. You want your predictions to be
correct 90% of the times, pick the score threshold where your precision
is closest to 0.9.</p>
<p>But we’re curious, as the real professional data scientists are. So we
need to know more about the data. We’ll calculate the recall. Recall is
a funky term, that shows how many <em>true positives</em> we have predicted out
all the positive values. We take the number of <em>true positives</em> seen so
far, just like for the precision. But now we divide it by the total
number of points with true label 1 in the evaluation dataset. That’s
right, the denominator for the recall is constant at each iteration, and
the nominator is ever-increasing. At the beginning of the loop when the
score threshold is at the highest, and we haven’t observed any true
positives, the recall is zero. At the end, when score threshold is at
the lowest score, the recall is the number of <em>true positives</em> divided
by the total number of points with label 1.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
</span><span data-line="2"><span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">))</span>
</span><span data-line="3"><span class="n">precisions</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">recalls</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">thresholds</span><span class="o">.</span><span class="n">shape</span>
</span></pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="p">((</span><span class="mi">51</span><span class="p">,),</span> <span class="p">(</span><span class="mi">51</span><span class="p">,),</span> <span class="p">(</span><span class="mi">51</span><span class="p">,))</span>
</span></pre></div>
</div>
</section>
<section id="lets-take-a-look">
<h2>Let’s take a look<a class="headerlink" href="#lets-take-a-look" title="Link to this heading">¶</a></h2>
<p>Okay, that was all good knowledge, thank you very much, but can you show
me some examples? How about we plot these 3 sequences against each
other?</p>
<p>First, all three lines on the same chart.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;$Precision$&#39;</span><span class="p">:</span> <span class="n">precisions</span><span class="p">,</span> <span class="s1">&#39;$Recall$&#39;</span><span class="p">:</span> <span class="n">recalls</span><span class="p">,</span> <span class="s1">&#39;$Threshold$&#39;</span><span class="p">:</span> <span class="n">thresholds</span><span class="p">})</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_23_0.png" src="../_images/12.64_23_0.png" />
<p>Magnificient! But not very helpful. We see that the threshold are just
sorted scores. We see recall starting at 1.0 and going down to zero. And
the precision starts somewhere around 0.5 and goes up (and sometimes
down) to 1.0.</p>
<p>How about we put recall as the X axis, and plot precision and thresholds
as Y.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;$Precision$&#39;</span><span class="p">:</span> <span class="n">precisions</span><span class="p">,</span> <span class="s1">&#39;$Recall$&#39;</span><span class="p">:</span> <span class="n">recalls</span><span class="p">,</span> <span class="s1">&#39;$Threshold$&#39;</span><span class="p">:</span> <span class="n">thresholds</span><span class="p">})</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;$Recall$&#39;</span><span class="p">);</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_25_0.png" src="../_images/12.64_25_0.png" />
<p>Yeah, that’s very close to what scikit plotted for us above. The steps
are not as pronounced, but that’s fine.</p>
<p>How about we go crazy and plot both precision and recall against the
threshold?</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span data-line="1"><span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;$Precision$&#39;</span><span class="p">:</span> <span class="n">precisions</span><span class="p">,</span> <span class="s1">&#39;$Recall$&#39;</span><span class="p">:</span> <span class="n">recalls</span><span class="p">,</span> <span class="s1">&#39;$Threshold$&#39;</span><span class="p">:</span> <span class="n">thresholds</span><span class="p">})</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;$Threshold$&#39;</span><span class="p">);</span>
</span></pre></div>
</div>
<img alt="../_images/12.64_27_0.png" src="../_images/12.64_27_0.png" />
<p>The lines cross! What a coincedence (it’s not). Funny, that the
threshold of the cross is about where we (no, you, against my better
judgement) eye-balled the sweet spot. Is there any theoretical
significance to this spot? I don’t think so. You don’t get the biggest
bang for your buck by jerking target precision for the system after
every evaluation. You want the target precision to be good and stable,
and preferrably decided by someone who understands the product, the
users, and also that murky statistical part, that precision doesn’t take
into account <em>false negatives</em> - predictions of label 0 when it’s
actually 1.</p>
</section>
</section>

        </article>
        <button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button>
        <div class="navigation flex print:hidden"><div class="navigation-prev">
    <a href="63-100q-open.html">
      <i class="i-lucide chevron-left"></i>
      <div class="page-info">
        <span>Previous</span><div class="title">100 questions for Washington state in Aug 2024</div></div>
    </a>
  </div><div class="navigation-next">
    <a href="65-firefox-reader-solarized-dark.html">
      <div class="page-info">
        <span>Next</span>
        <div class="title">Solarized Dark Theme for Firefox Reader View</div>
      </div>
      <i class="i-lucide chevron-right"></i>
    </a>
  </div></div>
        
      </div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2022, Peter Demin</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=fd6eb6e6"></script>
      <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script src="../_static/shibuya.js?v=cac61aee"></script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script></body>
</html>